{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "import pandas_datareader.data as web\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read stock data use pandas_datareader.data from web\n",
    "# Get Stock Data\n",
    "stk_tickers = ['MSFT', 'IBM', 'GOOGL']\n",
    "ccy_tickers = ['DEXJPUS', 'DEXUSUK']\n",
    "idx_tickers = ['SP500', 'DJIA', 'VIXCLS']\n",
    "stk_data = web.DataReader(stk_tickers, 'yahoo')\n",
    "ccy_data = web.DataReader(ccy_tickers, 'fred')\n",
    "idx_data = web.DataReader(idx_tickers, 'fred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes   Adj Close            \n",
      "Symbols          GOOGL         IBM\n",
      "Date                              \n",
      "2017-09-18   46.487499  108.947281\n",
      "2017-09-19   46.842999  108.826698\n",
      "2017-09-20   47.376999  109.949707\n",
      "2017-09-21   47.377499  109.482422\n",
      "2017-09-22   47.162998  109.384407\n",
      "...                ...         ...\n",
      "2022-09-09  110.650002  129.190002\n",
      "2022-09-12  110.860001  130.660004\n",
      "2022-09-13  104.320000  127.250000\n",
      "2022-09-14  105.000000  127.690002\n",
      "2022-09-15  102.910004  125.489998\n",
      "\n",
      "[1258 rows x 2 columns]\n",
      "            DEXJPUS  DEXUSUK\n",
      "DATE                        \n",
      "2017-09-18   111.48   1.3485\n",
      "2017-09-19   111.49   1.3517\n",
      "2017-09-20   111.50   1.3564\n",
      "2017-09-21   112.30   1.3576\n",
      "2017-09-22   112.01   1.3531\n",
      "...             ...      ...\n",
      "2022-09-05      NaN      NaN\n",
      "2022-09-06   142.95   1.1549\n",
      "2022-09-07   144.39   1.1473\n",
      "2022-09-08   144.05   1.1489\n",
      "2022-09-09   142.44   1.1600\n",
      "\n",
      "[1300 rows x 2 columns]\n",
      "              SP500      DJIA  VIXCLS\n",
      "DATE                                 \n",
      "2017-09-18  2503.87  22331.35   10.15\n",
      "2017-09-19  2506.65  22370.80   10.18\n",
      "2017-09-20  2508.24  22412.59    9.78\n",
      "2017-09-21  2500.60  22359.23    9.67\n",
      "2017-09-22  2502.22  22349.59    9.59\n",
      "...             ...       ...     ...\n",
      "2022-09-09  4067.36  32151.71   22.79\n",
      "2022-09-12  4110.41  32381.34   23.87\n",
      "2022-09-13  3932.69  31104.97   27.27\n",
      "2022-09-14  3946.01  31135.09   26.16\n",
      "2022-09-15  3901.35  30961.82     NaN\n",
      "\n",
      "[1304 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Select columns\n",
    "base = stk_data.loc[:, ('Adj Close', 'MSFT')]\n",
    "X1 = stk_data.loc[:, ('Adj Close', ('GOOGL', 'IBM'))]\n",
    "X2 = ccy_data\n",
    "X3 = idx_data\n",
    "print(X1)\n",
    "print(X2)\n",
    "print(X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.15774649, -0.59674325],\n",
       "       [-1.14650867, -0.6078857 ],\n",
       "       [-1.12962818, -0.50411389],\n",
       "       ...,\n",
       "       [ 0.6704188 ,  1.09452258],\n",
       "       [ 0.69191455,  1.13518108],\n",
       "       [ 0.62584688,  0.93188929]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Standardized data (X1, X2, X3) with kept index (date)\n",
    "standard_scaler = preprocessing.StandardScaler()\n",
    "sX1 = standard_scaler.fit_transform(X1.values)\n",
    "sX2 = standard_scaler.fit_transform(X2.values)\n",
    "sX3 = standard_scaler.fit_transform(X3.values)\n",
    "print(type(sX1))\n",
    "sX1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Attributes</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Symbols</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>IBM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-09-18</th>\n",
       "      <td>-1.157746</td>\n",
       "      <td>-0.596743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-19</th>\n",
       "      <td>-1.146509</td>\n",
       "      <td>-0.607886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-20</th>\n",
       "      <td>-1.129628</td>\n",
       "      <td>-0.504114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-21</th>\n",
       "      <td>-1.129612</td>\n",
       "      <td>-0.547293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-22</th>\n",
       "      <td>-1.136393</td>\n",
       "      <td>-0.556351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-09</th>\n",
       "      <td>0.870519</td>\n",
       "      <td>1.273789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-12</th>\n",
       "      <td>0.877157</td>\n",
       "      <td>1.409625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-13</th>\n",
       "      <td>0.670419</td>\n",
       "      <td>1.094523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-14</th>\n",
       "      <td>0.691915</td>\n",
       "      <td>1.135181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-15</th>\n",
       "      <td>0.625847</td>\n",
       "      <td>0.931889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1258 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Attributes Adj Close          \n",
       "Symbols        GOOGL       IBM\n",
       "Date                          \n",
       "2017-09-18 -1.157746 -0.596743\n",
       "2017-09-19 -1.146509 -0.607886\n",
       "2017-09-20 -1.129628 -0.504114\n",
       "2017-09-21 -1.129612 -0.547293\n",
       "2017-09-22 -1.136393 -0.556351\n",
       "...              ...       ...\n",
       "2022-09-09  0.870519  1.273789\n",
       "2022-09-12  0.877157  1.409625\n",
       "2022-09-13  0.670419  1.094523\n",
       "2022-09-14  0.691915  1.135181\n",
       "2022-09-15  0.625847  0.931889\n",
       "\n",
       "[1258 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sX1 = pd.DataFrame(index = X1.index,data = sX1,columns=X1.columns)\n",
    "sX2 = pd.DataFrame(index = X2.index,data = sX2,columns=X2.columns)\n",
    "sX3 = pd.DataFrame(index = X3.index,data = sX3,columns=X3.columns)\n",
    "sX1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Symbols</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>IBM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-09-18</th>\n",
       "      <td>46.487499</td>\n",
       "      <td>108.947281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-19</th>\n",
       "      <td>46.842999</td>\n",
       "      <td>108.826698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-20</th>\n",
       "      <td>47.376999</td>\n",
       "      <td>109.949707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-21</th>\n",
       "      <td>47.377499</td>\n",
       "      <td>109.482422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-22</th>\n",
       "      <td>47.162998</td>\n",
       "      <td>109.384407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-09</th>\n",
       "      <td>110.650002</td>\n",
       "      <td>129.190002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-12</th>\n",
       "      <td>110.860001</td>\n",
       "      <td>130.660004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-13</th>\n",
       "      <td>104.320000</td>\n",
       "      <td>127.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-14</th>\n",
       "      <td>105.000000</td>\n",
       "      <td>127.690002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-15</th>\n",
       "      <td>102.910004</td>\n",
       "      <td>125.489998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1258 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Symbols          GOOGL         IBM\n",
       "Date                              \n",
       "2017-09-18   46.487499  108.947281\n",
       "2017-09-19   46.842999  108.826698\n",
       "2017-09-20   47.376999  109.949707\n",
       "2017-09-21   47.377499  109.482422\n",
       "2017-09-22   47.162998  109.384407\n",
       "...                ...         ...\n",
       "2022-09-09  110.650002  129.190002\n",
       "2022-09-12  110.860001  130.660004\n",
       "2022-09-13  104.320000  127.250000\n",
       "2022-09-14  105.000000  127.690002\n",
       "2022-09-15  102.910004  125.489998\n",
       "\n",
       "[1258 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1['Adj Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Calculate ความแตกต่างของค่า ราคา 'Adj Close', 'MSFT’)ย้อนหลัง return_period วัน\n",
    "return_period = 1 #predict 1 วันข้างหน้า\n",
    "Y = base.shift(-return_period)\n",
    "X4_3DT = base.diff(3*return_period).shift(-3*return_period)\n",
    "X4_6DT = base.diff(6*return_period).shift(-6*return_period)\n",
    "X4_12DT = base.diff(12*return_period).shift(-12*return_period)\n",
    "X4 = pd.concat([X4_3DT, X4_6DT, X4_12DT], axis=1)\n",
    "X4.columns = ['MSFT_3DT', 'MSFT_6DT', 'MSFT_12DT']\n",
    "X4 = pd.DataFrame(standard_scaler.fit_transform(X4.values), index = X4.index,columns=X4.columns)\n",
    "\n",
    "# Forming Dataset\n",
    "X = pd.concat([sX1, sX2, sX3, X4], axis=1)\n",
    "dataset = pd.concat([Y, X], axis=1)\n",
    "print(type(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(Adj Close, MSFT)</th>\n",
       "      <th>(Adj Close, GOOGL)</th>\n",
       "      <th>(Adj Close, IBM)</th>\n",
       "      <th>DEXJPUS</th>\n",
       "      <th>DEXUSUK</th>\n",
       "      <th>SP500</th>\n",
       "      <th>DJIA</th>\n",
       "      <th>VIXCLS</th>\n",
       "      <th>MSFT_3DT</th>\n",
       "      <th>MSFT_6DT</th>\n",
       "      <th>MSFT_12DT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-09-18</th>\n",
       "      <td>70.887177</td>\n",
       "      <td>-1.157746</td>\n",
       "      <td>-0.596743</td>\n",
       "      <td>-0.034125</td>\n",
       "      <td>0.632440</td>\n",
       "      <td>-1.266457</td>\n",
       "      <td>-1.503384</td>\n",
       "      <td>-1.182579</td>\n",
       "      <td>-0.231712</td>\n",
       "      <td>-0.342111</td>\n",
       "      <td>-0.209739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-19</th>\n",
       "      <td>70.417336</td>\n",
       "      <td>-1.146509</td>\n",
       "      <td>-0.607886</td>\n",
       "      <td>-0.032778</td>\n",
       "      <td>0.687607</td>\n",
       "      <td>-1.262425</td>\n",
       "      <td>-1.493851</td>\n",
       "      <td>-1.179130</td>\n",
       "      <td>-0.244900</td>\n",
       "      <td>-0.304913</td>\n",
       "      <td>-0.122156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-20</th>\n",
       "      <td>69.731415</td>\n",
       "      <td>-1.129628</td>\n",
       "      <td>-0.504114</td>\n",
       "      <td>-0.031431</td>\n",
       "      <td>0.768632</td>\n",
       "      <td>-1.260119</td>\n",
       "      <td>-1.483753</td>\n",
       "      <td>-1.225117</td>\n",
       "      <td>-0.352024</td>\n",
       "      <td>-0.242510</td>\n",
       "      <td>-0.075736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-21</th>\n",
       "      <td>69.919334</td>\n",
       "      <td>-1.129612</td>\n",
       "      <td>-0.547293</td>\n",
       "      <td>0.076321</td>\n",
       "      <td>0.789320</td>\n",
       "      <td>-1.271199</td>\n",
       "      <td>-1.496647</td>\n",
       "      <td>-1.237764</td>\n",
       "      <td>-0.231716</td>\n",
       "      <td>-0.080517</td>\n",
       "      <td>0.013595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-22</th>\n",
       "      <td>68.838737</td>\n",
       "      <td>-1.136393</td>\n",
       "      <td>-0.556351</td>\n",
       "      <td>0.037261</td>\n",
       "      <td>0.711742</td>\n",
       "      <td>-1.268850</td>\n",
       "      <td>-1.498977</td>\n",
       "      <td>-1.246961</td>\n",
       "      <td>-0.167438</td>\n",
       "      <td>-0.090120</td>\n",
       "      <td>-0.003920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-23</th>\n",
       "      <td>275.790009</td>\n",
       "      <td>0.971991</td>\n",
       "      <td>1.786638</td>\n",
       "      <td>3.316975</td>\n",
       "      <td>-2.196569</td>\n",
       "      <td>1.089918</td>\n",
       "      <td>1.052826</td>\n",
       "      <td>0.422379</td>\n",
       "      <td>-1.539710</td>\n",
       "      <td>-2.025844</td>\n",
       "      <td>-1.285195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-24</th>\n",
       "      <td>278.850006</td>\n",
       "      <td>0.966618</td>\n",
       "      <td>1.647105</td>\n",
       "      <td>3.392402</td>\n",
       "      <td>-2.268975</td>\n",
       "      <td>1.107379</td>\n",
       "      <td>1.067237</td>\n",
       "      <td>0.274069</td>\n",
       "      <td>-1.927336</td>\n",
       "      <td>-2.079481</td>\n",
       "      <td>-1.020488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-25</th>\n",
       "      <td>268.089996</td>\n",
       "      <td>1.060187</td>\n",
       "      <td>1.716409</td>\n",
       "      <td>3.380280</td>\n",
       "      <td>-2.267251</td>\n",
       "      <td>1.191998</td>\n",
       "      <td>1.145181</td>\n",
       "      <td>0.154502</td>\n",
       "      <td>-2.860450</td>\n",
       "      <td>-3.024489</td>\n",
       "      <td>-2.672114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-26</th>\n",
       "      <td>265.230011</td>\n",
       "      <td>0.860719</td>\n",
       "      <td>1.383751</td>\n",
       "      <td>3.412605</td>\n",
       "      <td>-2.310350</td>\n",
       "      <td>0.986853</td>\n",
       "      <td>0.901508</td>\n",
       "      <td>0.589083</td>\n",
       "      <td>-1.236271</td>\n",
       "      <td>-2.009242</td>\n",
       "      <td>-1.647769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-29</th>\n",
       "      <td>262.970001</td>\n",
       "      <td>0.831637</td>\n",
       "      <td>1.377282</td>\n",
       "      <td>3.637538</td>\n",
       "      <td>-2.413787</td>\n",
       "      <td>0.947625</td>\n",
       "      <td>0.856946</td>\n",
       "      <td>0.663812</td>\n",
       "      <td>-0.922314</td>\n",
       "      <td>-1.025925</td>\n",
       "      <td>-2.018734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1229 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            (Adj Close, MSFT)  (Adj Close, GOOGL)  (Adj Close, IBM)   DEXJPUS  \\\n",
       "2017-09-18          70.887177           -1.157746         -0.596743 -0.034125   \n",
       "2017-09-19          70.417336           -1.146509         -0.607886 -0.032778   \n",
       "2017-09-20          69.731415           -1.129628         -0.504114 -0.031431   \n",
       "2017-09-21          69.919334           -1.129612         -0.547293  0.076321   \n",
       "2017-09-22          68.838737           -1.136393         -0.556351  0.037261   \n",
       "...                       ...                 ...               ...       ...   \n",
       "2022-08-23         275.790009            0.971991          1.786638  3.316975   \n",
       "2022-08-24         278.850006            0.966618          1.647105  3.392402   \n",
       "2022-08-25         268.089996            1.060187          1.716409  3.380280   \n",
       "2022-08-26         265.230011            0.860719          1.383751  3.412605   \n",
       "2022-08-29         262.970001            0.831637          1.377282  3.637538   \n",
       "\n",
       "             DEXUSUK     SP500      DJIA    VIXCLS  MSFT_3DT  MSFT_6DT  \\\n",
       "2017-09-18  0.632440 -1.266457 -1.503384 -1.182579 -0.231712 -0.342111   \n",
       "2017-09-19  0.687607 -1.262425 -1.493851 -1.179130 -0.244900 -0.304913   \n",
       "2017-09-20  0.768632 -1.260119 -1.483753 -1.225117 -0.352024 -0.242510   \n",
       "2017-09-21  0.789320 -1.271199 -1.496647 -1.237764 -0.231716 -0.080517   \n",
       "2017-09-22  0.711742 -1.268850 -1.498977 -1.246961 -0.167438 -0.090120   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2022-08-23 -2.196569  1.089918  1.052826  0.422379 -1.539710 -2.025844   \n",
       "2022-08-24 -2.268975  1.107379  1.067237  0.274069 -1.927336 -2.079481   \n",
       "2022-08-25 -2.267251  1.191998  1.145181  0.154502 -2.860450 -3.024489   \n",
       "2022-08-26 -2.310350  0.986853  0.901508  0.589083 -1.236271 -2.009242   \n",
       "2022-08-29 -2.413787  0.947625  0.856946  0.663812 -0.922314 -1.025925   \n",
       "\n",
       "            MSFT_12DT  \n",
       "2017-09-18  -0.209739  \n",
       "2017-09-19  -0.122156  \n",
       "2017-09-20  -0.075736  \n",
       "2017-09-21   0.013595  \n",
       "2017-09-22  -0.003920  \n",
       "...               ...  \n",
       "2022-08-23  -1.285195  \n",
       "2022-08-24  -1.020488  \n",
       "2022-08-25  -2.672114  \n",
       "2022-08-26  -1.647769  \n",
       "2022-08-29  -2.018734  \n",
       "\n",
       "[1229 rows x 11 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dropna(inplace=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1229 entries, 2017-09-18 to 2022-08-29\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   (Adj Close, MSFT)   1229 non-null   float64\n",
      " 1   (Adj Close, GOOGL)  1229 non-null   float64\n",
      " 2   (Adj Close, IBM)    1229 non-null   float64\n",
      " 3   DEXJPUS             1229 non-null   float64\n",
      " 4   DEXUSUK             1229 non-null   float64\n",
      " 5   SP500               1229 non-null   float64\n",
      " 6   DJIA                1229 non-null   float64\n",
      " 7   VIXCLS              1229 non-null   float64\n",
      " 8   MSFT_3DT            1229 non-null   float64\n",
      " 9   MSFT_6DT            1229 non-null   float64\n",
      " 10  MSFT_12DT           1229 non-null   float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 115.2 KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Adj Close\n",
      "            MSFT\n",
      "0      70.887177\n",
      "1      70.417336\n",
      "2      69.731415\n",
      "3      69.919334\n",
      "4      68.838737\n",
      "...          ...\n",
      "1224  275.790009\n",
      "1225  278.850006\n",
      "1226  268.089996\n",
      "1227  265.230011\n",
      "1228  262.970001\n",
      "\n",
      "[1229 rows x 1 columns]\n",
      "      (Adj Close, GOOGL)  (Adj Close, IBM)   DEXJPUS   DEXUSUK     SP500  \\\n",
      "0              -1.157746         -0.596743 -0.034125  0.632440 -1.266457   \n",
      "1              -1.146509         -0.607886 -0.032778  0.687607 -1.262425   \n",
      "2              -1.129628         -0.504114 -0.031431  0.768632 -1.260119   \n",
      "3              -1.129612         -0.547293  0.076321  0.789320 -1.271199   \n",
      "4              -1.136393         -0.556351  0.037261  0.711742 -1.268850   \n",
      "...                  ...               ...       ...       ...       ...   \n",
      "1224            0.971991          1.786638  3.316975 -2.196569  1.089918   \n",
      "1225            0.966618          1.647105  3.392402 -2.268975  1.107379   \n",
      "1226            1.060187          1.716409  3.380280 -2.267251  1.191998   \n",
      "1227            0.860719          1.383751  3.412605 -2.310350  0.986853   \n",
      "1228            0.831637          1.377282  3.637538 -2.413787  0.947625   \n",
      "\n",
      "          DJIA    VIXCLS  MSFT_3DT  MSFT_6DT  MSFT_12DT  \n",
      "0    -1.503384 -1.182579 -0.231712 -0.342111  -0.209739  \n",
      "1    -1.493851 -1.179130 -0.244900 -0.304913  -0.122156  \n",
      "2    -1.483753 -1.225117 -0.352024 -0.242510  -0.075736  \n",
      "3    -1.496647 -1.237764 -0.231716 -0.080517   0.013595  \n",
      "4    -1.498977 -1.246961 -0.167438 -0.090120  -0.003920  \n",
      "...        ...       ...       ...       ...        ...  \n",
      "1224  1.052826  0.422379 -1.539710 -2.025844  -1.285195  \n",
      "1225  1.067237  0.274069 -1.927336 -2.079481  -1.020488  \n",
      "1226  1.145181  0.154502 -2.860450 -3.024489  -2.672114  \n",
      "1227  0.901508  0.589083 -1.236271 -2.009242  -1.647769  \n",
      "1228  0.856946  0.663812 -0.922314 -1.025925  -2.018734  \n",
      "\n",
      "[1229 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "Y = pd.DataFrame(dataset[dataset.columns[0]].reset_index(drop=True))\n",
    "X = pd.DataFrame(dataset[dataset.columns[1:]].reset_index(drop=True))\n",
    "print(Y)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(Adj Close, GOOGL)</th>\n",
       "      <th>(Adj Close, IBM)</th>\n",
       "      <th>DEXJPUS</th>\n",
       "      <th>DEXUSUK</th>\n",
       "      <th>SP500</th>\n",
       "      <th>DJIA</th>\n",
       "      <th>VIXCLS</th>\n",
       "      <th>MSFT_3DT</th>\n",
       "      <th>MSFT_6DT</th>\n",
       "      <th>MSFT_12DT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(Adj Close, GOOGL)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.601793</td>\n",
       "      <td>0.392870</td>\n",
       "      <td>0.266160</td>\n",
       "      <td>0.985415</td>\n",
       "      <td>0.960172</td>\n",
       "      <td>0.153017</td>\n",
       "      <td>-0.053557</td>\n",
       "      <td>-0.076005</td>\n",
       "      <td>-0.102324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Adj Close, IBM)</th>\n",
       "      <td>0.601793</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.570644</td>\n",
       "      <td>0.228632</td>\n",
       "      <td>0.608928</td>\n",
       "      <td>0.661023</td>\n",
       "      <td>-0.285608</td>\n",
       "      <td>-0.084682</td>\n",
       "      <td>-0.132809</td>\n",
       "      <td>-0.174050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEXJPUS</th>\n",
       "      <td>0.392870</td>\n",
       "      <td>0.570644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.365275</td>\n",
       "      <td>0.350181</td>\n",
       "      <td>0.343815</td>\n",
       "      <td>0.050443</td>\n",
       "      <td>-0.075823</td>\n",
       "      <td>-0.114391</td>\n",
       "      <td>-0.162015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEXUSUK</th>\n",
       "      <td>0.266160</td>\n",
       "      <td>0.228632</td>\n",
       "      <td>-0.365275</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.278266</td>\n",
       "      <td>0.322238</td>\n",
       "      <td>-0.327849</td>\n",
       "      <td>0.004784</td>\n",
       "      <td>0.013394</td>\n",
       "      <td>0.026606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>0.985415</td>\n",
       "      <td>0.608928</td>\n",
       "      <td>0.350181</td>\n",
       "      <td>0.278266</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986195</td>\n",
       "      <td>0.108280</td>\n",
       "      <td>-0.060321</td>\n",
       "      <td>-0.088016</td>\n",
       "      <td>-0.120899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DJIA</th>\n",
       "      <td>0.960172</td>\n",
       "      <td>0.661023</td>\n",
       "      <td>0.343815</td>\n",
       "      <td>0.322238</td>\n",
       "      <td>0.986195</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005292</td>\n",
       "      <td>-0.062945</td>\n",
       "      <td>-0.091934</td>\n",
       "      <td>-0.123991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIXCLS</th>\n",
       "      <td>0.153017</td>\n",
       "      <td>-0.285608</td>\n",
       "      <td>0.050443</td>\n",
       "      <td>-0.327849</td>\n",
       "      <td>0.108280</td>\n",
       "      <td>-0.005292</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.059809</td>\n",
       "      <td>0.081869</td>\n",
       "      <td>0.109965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT_3DT</th>\n",
       "      <td>-0.053557</td>\n",
       "      <td>-0.084682</td>\n",
       "      <td>-0.075823</td>\n",
       "      <td>0.004784</td>\n",
       "      <td>-0.060321</td>\n",
       "      <td>-0.062945</td>\n",
       "      <td>0.059809</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.688943</td>\n",
       "      <td>0.491058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT_6DT</th>\n",
       "      <td>-0.076005</td>\n",
       "      <td>-0.132809</td>\n",
       "      <td>-0.114391</td>\n",
       "      <td>0.013394</td>\n",
       "      <td>-0.088016</td>\n",
       "      <td>-0.091934</td>\n",
       "      <td>0.081869</td>\n",
       "      <td>0.688943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.680495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT_12DT</th>\n",
       "      <td>-0.102324</td>\n",
       "      <td>-0.174050</td>\n",
       "      <td>-0.162015</td>\n",
       "      <td>0.026606</td>\n",
       "      <td>-0.120899</td>\n",
       "      <td>-0.123991</td>\n",
       "      <td>0.109965</td>\n",
       "      <td>0.491058</td>\n",
       "      <td>0.680495</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    (Adj Close, GOOGL)  (Adj Close, IBM)   DEXJPUS   DEXUSUK  \\\n",
       "(Adj Close, GOOGL)            1.000000          0.601793  0.392870  0.266160   \n",
       "(Adj Close, IBM)              0.601793          1.000000  0.570644  0.228632   \n",
       "DEXJPUS                       0.392870          0.570644  1.000000 -0.365275   \n",
       "DEXUSUK                       0.266160          0.228632 -0.365275  1.000000   \n",
       "SP500                         0.985415          0.608928  0.350181  0.278266   \n",
       "DJIA                          0.960172          0.661023  0.343815  0.322238   \n",
       "VIXCLS                        0.153017         -0.285608  0.050443 -0.327849   \n",
       "MSFT_3DT                     -0.053557         -0.084682 -0.075823  0.004784   \n",
       "MSFT_6DT                     -0.076005         -0.132809 -0.114391  0.013394   \n",
       "MSFT_12DT                    -0.102324         -0.174050 -0.162015  0.026606   \n",
       "\n",
       "                       SP500      DJIA    VIXCLS  MSFT_3DT  MSFT_6DT  \\\n",
       "(Adj Close, GOOGL)  0.985415  0.960172  0.153017 -0.053557 -0.076005   \n",
       "(Adj Close, IBM)    0.608928  0.661023 -0.285608 -0.084682 -0.132809   \n",
       "DEXJPUS             0.350181  0.343815  0.050443 -0.075823 -0.114391   \n",
       "DEXUSUK             0.278266  0.322238 -0.327849  0.004784  0.013394   \n",
       "SP500               1.000000  0.986195  0.108280 -0.060321 -0.088016   \n",
       "DJIA                0.986195  1.000000 -0.005292 -0.062945 -0.091934   \n",
       "VIXCLS              0.108280 -0.005292  1.000000  0.059809  0.081869   \n",
       "MSFT_3DT           -0.060321 -0.062945  0.059809  1.000000  0.688943   \n",
       "MSFT_6DT           -0.088016 -0.091934  0.081869  0.688943  1.000000   \n",
       "MSFT_12DT          -0.120899 -0.123991  0.109965  0.491058  0.680495   \n",
       "\n",
       "                    MSFT_12DT  \n",
       "(Adj Close, GOOGL)  -0.102324  \n",
       "(Adj Close, IBM)    -0.174050  \n",
       "DEXJPUS             -0.162015  \n",
       "DEXUSUK              0.026606  \n",
       "SP500               -0.120899  \n",
       "DJIA                -0.123991  \n",
       "VIXCLS               0.109965  \n",
       "MSFT_3DT             0.491058  \n",
       "MSFT_6DT             0.680495  \n",
       "MSFT_12DT            1.000000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Adj Close', 'GOOGL'), 'SP500']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower = pd.DataFrame(np.tril(X.corr(),-1),columns = X.columns)\n",
    "to_drop = [column for column in lower.columns if any(lower[column] > 0.9)]\n",
    "to_drop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(columns=to_drop,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(Adj Close, IBM)</th>\n",
       "      <th>DEXJPUS</th>\n",
       "      <th>DEXUSUK</th>\n",
       "      <th>DJIA</th>\n",
       "      <th>VIXCLS</th>\n",
       "      <th>MSFT_3DT</th>\n",
       "      <th>MSFT_6DT</th>\n",
       "      <th>MSFT_12DT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.596743</td>\n",
       "      <td>-0.034125</td>\n",
       "      <td>0.632440</td>\n",
       "      <td>-1.503384</td>\n",
       "      <td>-1.182579</td>\n",
       "      <td>-0.231712</td>\n",
       "      <td>-0.342111</td>\n",
       "      <td>-0.209739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.607886</td>\n",
       "      <td>-0.032778</td>\n",
       "      <td>0.687607</td>\n",
       "      <td>-1.493851</td>\n",
       "      <td>-1.179130</td>\n",
       "      <td>-0.244900</td>\n",
       "      <td>-0.304913</td>\n",
       "      <td>-0.122156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.504114</td>\n",
       "      <td>-0.031431</td>\n",
       "      <td>0.768632</td>\n",
       "      <td>-1.483753</td>\n",
       "      <td>-1.225117</td>\n",
       "      <td>-0.352024</td>\n",
       "      <td>-0.242510</td>\n",
       "      <td>-0.075736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.547293</td>\n",
       "      <td>0.076321</td>\n",
       "      <td>0.789320</td>\n",
       "      <td>-1.496647</td>\n",
       "      <td>-1.237764</td>\n",
       "      <td>-0.231716</td>\n",
       "      <td>-0.080517</td>\n",
       "      <td>0.013595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.556351</td>\n",
       "      <td>0.037261</td>\n",
       "      <td>0.711742</td>\n",
       "      <td>-1.498977</td>\n",
       "      <td>-1.246961</td>\n",
       "      <td>-0.167438</td>\n",
       "      <td>-0.090120</td>\n",
       "      <td>-0.003920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>1.786638</td>\n",
       "      <td>3.316975</td>\n",
       "      <td>-2.196569</td>\n",
       "      <td>1.052826</td>\n",
       "      <td>0.422379</td>\n",
       "      <td>-1.539710</td>\n",
       "      <td>-2.025844</td>\n",
       "      <td>-1.285195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>1.647105</td>\n",
       "      <td>3.392402</td>\n",
       "      <td>-2.268975</td>\n",
       "      <td>1.067237</td>\n",
       "      <td>0.274069</td>\n",
       "      <td>-1.927336</td>\n",
       "      <td>-2.079481</td>\n",
       "      <td>-1.020488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>1.716409</td>\n",
       "      <td>3.380280</td>\n",
       "      <td>-2.267251</td>\n",
       "      <td>1.145181</td>\n",
       "      <td>0.154502</td>\n",
       "      <td>-2.860450</td>\n",
       "      <td>-3.024489</td>\n",
       "      <td>-2.672114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>1.383751</td>\n",
       "      <td>3.412605</td>\n",
       "      <td>-2.310350</td>\n",
       "      <td>0.901508</td>\n",
       "      <td>0.589083</td>\n",
       "      <td>-1.236271</td>\n",
       "      <td>-2.009242</td>\n",
       "      <td>-1.647769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>1.377282</td>\n",
       "      <td>3.637538</td>\n",
       "      <td>-2.413787</td>\n",
       "      <td>0.856946</td>\n",
       "      <td>0.663812</td>\n",
       "      <td>-0.922314</td>\n",
       "      <td>-1.025925</td>\n",
       "      <td>-2.018734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1229 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      (Adj Close, IBM)   DEXJPUS   DEXUSUK      DJIA    VIXCLS  MSFT_3DT  \\\n",
       "0            -0.596743 -0.034125  0.632440 -1.503384 -1.182579 -0.231712   \n",
       "1            -0.607886 -0.032778  0.687607 -1.493851 -1.179130 -0.244900   \n",
       "2            -0.504114 -0.031431  0.768632 -1.483753 -1.225117 -0.352024   \n",
       "3            -0.547293  0.076321  0.789320 -1.496647 -1.237764 -0.231716   \n",
       "4            -0.556351  0.037261  0.711742 -1.498977 -1.246961 -0.167438   \n",
       "...                ...       ...       ...       ...       ...       ...   \n",
       "1224          1.786638  3.316975 -2.196569  1.052826  0.422379 -1.539710   \n",
       "1225          1.647105  3.392402 -2.268975  1.067237  0.274069 -1.927336   \n",
       "1226          1.716409  3.380280 -2.267251  1.145181  0.154502 -2.860450   \n",
       "1227          1.383751  3.412605 -2.310350  0.901508  0.589083 -1.236271   \n",
       "1228          1.377282  3.637538 -2.413787  0.856946  0.663812 -0.922314   \n",
       "\n",
       "      MSFT_6DT  MSFT_12DT  \n",
       "0    -0.342111  -0.209739  \n",
       "1    -0.304913  -0.122156  \n",
       "2    -0.242510  -0.075736  \n",
       "3    -0.080517   0.013595  \n",
       "4    -0.090120  -0.003920  \n",
       "...        ...        ...  \n",
       "1224 -2.025844  -1.285195  \n",
       "1225 -2.079481  -1.020488  \n",
       "1226 -3.024489  -2.672114  \n",
       "1227 -2.009242  -1.647769  \n",
       "1228 -1.025925  -2.018734  \n",
       "\n",
       "[1229 rows x 8 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle spilt\n",
    "# Rseed = 55\n",
    "# x_train_set , x_test, y_train_set , y_test = train_test_split(X,Y,test_size= 0.3,random_state= Rseed)\n",
    "# x_train,x_validate,y_train,y_validate = train_test_split(x_train_set,y_train_set,test_size=0.3 ,random_state= Rseed)\n",
    "from math import ceil, floor\n",
    "#test_size =  ceil(0.3 * len( X ))\n",
    "train_size = floor(0.7 * len( X ))\n",
    "X_train, X_test = X[0:train_size], X[train_size:len(X)]\n",
    "Y_train, Y_test = Y[0:train_size], Y[train_size:len(X)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation Model\n",
    "# set k-fold crossvalidation with shuffle\n",
    "num_fold = 50\n",
    "seed = 500\n",
    "kfold = KFold(n_splits=num_fold, shuffle = True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Linear Model  SVR_linear   SVR_rbf  SVR_poly\n",
      "0       0.951303    0.670530  0.019518  0.173833\n",
      "1       0.917185    0.683658  0.027451  0.095742\n",
      "2       0.836251    0.567634 -0.104534 -0.031191\n",
      "3       0.905207    0.730760  0.027433  0.169083\n",
      "4       0.894350    0.598269  0.005043  0.088826\n",
      "5       0.896085    0.558653 -0.019877  0.038970\n",
      "6       0.856869    0.514173 -0.044504  0.026951\n",
      "7       0.937798    0.672313  0.030261  0.112382\n",
      "8       0.888565    0.757325  0.041377  0.267617\n",
      "9       0.879824    0.573288 -0.013639  0.071786\n",
      "10      0.831225    0.804555 -0.049196  0.171895\n",
      "11      0.781404    0.517532  0.038957  0.121566\n",
      "12      0.879920    0.529494  0.026707  0.275540\n",
      "13      0.894119    0.649538  0.008895  0.062387\n",
      "14      0.789746    0.746150 -0.152170  0.118347\n",
      "15      0.832228    0.532498 -0.047910  0.102393\n",
      "16      0.872531    0.419043 -0.107897  0.072411\n",
      "17      0.892607    0.550551 -0.173225 -0.065669\n",
      "18      0.930662    0.477511 -0.155032 -0.069804\n",
      "19      0.932995    0.646986  0.015684  0.213939\n",
      "20      0.925402    0.569628 -0.054552 -0.022117\n",
      "21      0.747747    0.621928 -0.222074  0.053870\n",
      "22      0.841342    0.472140 -0.085592 -0.009167\n",
      "23      0.880550    0.675226  0.010389  0.295628\n",
      "24      0.892689    0.627784  0.015199  0.100522\n",
      "25      0.822301    0.497729 -0.001658 -0.071576\n",
      "26      0.849257    0.574669 -0.014838  0.143952\n",
      "27      0.812713    0.770087  0.005920  0.240304\n",
      "28      0.748080    0.567456 -0.163598 -0.077982\n",
      "29      0.924111    0.512430 -0.184347 -0.154779\n",
      "30      0.727990    0.661903  0.016688  0.067290\n",
      "31      0.800558    0.556996 -0.067050 -0.045792\n",
      "32      0.881830    0.573187 -0.028704  0.021620\n",
      "33      0.914194    0.763233  0.042604  0.235403\n",
      "34      0.905236    0.601888 -0.004879  0.079721\n",
      "35      0.907999    0.755710  0.039268  0.150591\n",
      "36      0.896748    0.659169  0.025548  0.131644\n",
      "37      0.965451    0.639280 -0.064931  0.054960\n",
      "38      0.914521    0.649454  0.028193  0.152359\n",
      "39      0.945301    0.793643  0.039885  0.161622\n",
      "40      0.727024    0.576511 -0.078663  0.062385\n",
      "41      0.755602    0.576844 -0.018224  0.052747\n",
      "42      0.909483    0.509271 -0.401700 -0.374481\n",
      "43      0.906059    0.136964 -0.793685 -0.754568\n",
      "44      0.830748    0.531401 -0.195997 -0.153588\n",
      "45      0.893133    0.616609 -0.015703  0.040500\n",
      "46      0.830269    0.522934 -0.176302 -0.164188\n",
      "47      0.851087    0.700343  0.026621  0.137173\n",
      "48      0.703997    0.561004  0.027327  0.121504\n",
      "49      0.949787    0.387558 -0.420021 -0.342178\n",
      "   AVG Linear Model  AVG SVR_linear  AVG SVR_rbf  AVG SVC_poly\n",
      "0          0.865242        0.597269    -0.066831      0.043008\n",
      "    Linear Model  SVR_linear   SVR_rbf  SVR_poly\n",
      "0       0.951303    0.937195  0.213282  0.685307\n",
      "1       0.917185    0.906128  0.236302  0.527651\n",
      "2       0.836251    0.776490  0.103687  0.491751\n",
      "3       0.905207    0.898096  0.283459  0.612850\n",
      "4       0.894350    0.860681  0.165650  0.479033\n",
      "5       0.896085    0.888838  0.098505  0.482605\n",
      "6       0.856869    0.825657  0.116204  0.495047\n",
      "7       0.937798    0.926206  0.227384  0.558332\n",
      "8       0.888565    0.906763  0.310918  0.747080\n",
      "9       0.879824    0.844171  0.154980  0.521420\n",
      "10      0.831225    0.840356  0.345593  0.739348\n",
      "11      0.781404    0.750682  0.274774  0.590030\n",
      "12      0.879920    0.865451  0.190256  0.732786\n",
      "13      0.894119    0.884800  0.174246  0.465382\n",
      "14      0.789746    0.852287  0.249868  0.788757\n",
      "15      0.832228    0.839587  0.110945  0.618742\n",
      "16      0.872531    0.839517  0.060497  0.239524\n",
      "17      0.892607    0.876026 -0.022749  0.500542\n",
      "18      0.930662    0.903575 -0.018950  0.464312\n",
      "19      0.932995    0.951423  0.158091  0.715696\n",
      "20      0.925402    0.915917  0.099399  0.380094\n",
      "21      0.747747    0.792790  0.216801  0.670340\n",
      "22      0.841342    0.808224  0.047019  0.426556\n",
      "23      0.880550    0.863257  0.266377  0.481995\n",
      "24      0.892689    0.841511  0.240022  0.362484\n",
      "25      0.822301    0.801863  0.202735  0.181005\n",
      "26      0.849257    0.826971  0.158841  0.578912\n",
      "27      0.812713    0.799917  0.369818  0.707499\n",
      "28      0.748080    0.748523  0.045776  0.392339\n",
      "29      0.924111    0.900537 -0.045564  0.363042\n",
      "30      0.727990    0.752844  0.204447  0.588450\n",
      "31      0.800558    0.736468  0.110115  0.392713\n",
      "32      0.881830    0.860660  0.164740  0.469523\n",
      "33      0.914194    0.898215  0.309899  0.652023\n",
      "34      0.905236    0.894130  0.141792  0.559210\n",
      "35      0.907999    0.915972  0.285046  0.634016\n",
      "36      0.896748    0.906300  0.199575  0.587022\n",
      "37      0.965451    0.974091  0.084148  0.482243\n",
      "38      0.914521    0.902498  0.228642  0.381023\n",
      "39      0.945301    0.956000  0.291800  0.657692\n",
      "40      0.727024    0.699387  0.228487  0.374777\n",
      "41      0.755602    0.753886  0.166179  0.414544\n",
      "42      0.909483    0.863351 -0.177343  0.224983\n",
      "43      0.906059    0.890116 -0.709009 -0.048326\n",
      "44      0.830748    0.799932  0.056937 -0.084404\n",
      "45      0.893133    0.867226  0.155122  0.495044\n",
      "46      0.830269    0.828908 -0.039366  0.340699\n",
      "47      0.851087    0.871070  0.295738  0.620798\n",
      "48      0.703997    0.592160  0.287087  0.361608\n",
      "49      0.949787    0.939239 -0.324212  0.217436\n",
      "   AVG Linear Model  AVG SVR_linear  AVG SVR_rbf  AVG SVC_poly\n",
      "0          0.865242        0.851518      0.13988      0.486431\n",
      "    Linear Model  SVR_linear   SVR_rbf  SVR_poly\n",
      "0       0.951303    0.942186  0.850893  0.907978\n",
      "1       0.917185    0.907161  0.855784  0.902560\n",
      "2       0.836251    0.784578  0.782790  0.881924\n",
      "3       0.905207    0.900039  0.867899  0.793334\n",
      "4       0.894350    0.860238  0.792424  0.925178\n",
      "5       0.896085    0.895338  0.748566  0.857322\n",
      "6       0.856869    0.839511  0.725543  0.814947\n",
      "7       0.937798    0.932711  0.823694  0.913251\n",
      "8       0.888565    0.900730  0.862849  0.817912\n",
      "9       0.879824    0.849044  0.755061  0.910968\n",
      "10      0.831225    0.810018  0.877303  0.824366\n",
      "11      0.781404    0.785565  0.843538  0.736911\n",
      "12      0.879920    0.881833  0.746372  0.952639\n",
      "13      0.894119    0.891234  0.802349  0.857470\n",
      "14      0.789746    0.842104  0.824314  0.860793\n",
      "15      0.832228    0.835904  0.760096  0.892155\n",
      "16      0.872531    0.853306  0.727481  0.882354\n",
      "17      0.892607    0.883253  0.790661  0.900747\n",
      "18      0.930662    0.919479  0.785668  0.920721\n",
      "19      0.932995    0.950445  0.878071  0.861036\n",
      "20      0.925402    0.926244  0.811734  0.905896\n",
      "21      0.747747    0.793588  0.691205  0.855133\n",
      "22      0.841342    0.818687  0.760327  0.811822\n",
      "23      0.880550    0.865316  0.838734  0.822244\n",
      "24      0.892689    0.862506  0.709349  0.736055\n",
      "25      0.822301    0.811550  0.737260  0.730381\n",
      "26      0.849257    0.834664  0.705242  0.780794\n",
      "27      0.812713    0.781973  0.812835  0.677239\n",
      "28      0.748080    0.742035  0.730712  0.737535\n",
      "29      0.924111    0.901422  0.785674  0.922220\n",
      "30      0.727990    0.743946  0.768524  0.849208\n",
      "31      0.800558    0.742027  0.740790  0.856550\n",
      "32      0.881830    0.866311  0.850302  0.855410\n",
      "33      0.914194    0.897315  0.885246  0.836777\n",
      "34      0.905236    0.897797  0.796061  0.873632\n",
      "35      0.907999    0.906443  0.910275  0.873197\n",
      "36      0.896748    0.909993  0.812678  0.944423\n",
      "37      0.965451    0.971761  0.881146  0.857803\n",
      "38      0.914521    0.911337  0.826024  0.901616\n",
      "39      0.945301    0.947996  0.938119  0.855185\n",
      "40      0.727024    0.739155  0.582617  0.670859\n",
      "41      0.755602    0.754276  0.709483  0.741530\n",
      "42      0.909483    0.867219  0.763824  0.881227\n",
      "43      0.906059    0.902479  0.608173  0.830233\n",
      "44      0.830748    0.804785  0.795156  0.787085\n",
      "45      0.893133    0.865757  0.810700  0.913411\n",
      "46      0.830269    0.829989  0.800469  0.868500\n",
      "47      0.851087    0.869617  0.858717  0.907417\n",
      "48      0.703997    0.605124  0.624538  0.761926\n",
      "49      0.949787    0.942667  0.745987  0.819119\n",
      "   AVG Linear Model  AVG SVR_linear  AVG SVR_rbf  AVG SVC_poly\n",
      "0          0.865242        0.855573     0.787865       0.84558\n",
      "    Linear Model  SVR_linear   SVR_rbf  SVR_poly\n",
      "0       0.951303    0.942569  0.966558  0.921969\n",
      "1       0.917185    0.907403  0.936431  0.917896\n",
      "2       0.836251    0.782189  0.868713  0.891939\n",
      "3       0.905207    0.900121  0.939175  0.818285\n",
      "4       0.894350    0.861142  0.918034  0.942100\n",
      "5       0.896085    0.895910  0.924181  0.871129\n",
      "6       0.856869    0.837352  0.895047  0.848027\n",
      "7       0.937798    0.932451  0.952451  0.889343\n",
      "8       0.888565    0.896453  0.932287  0.834588\n",
      "9       0.879824    0.849013  0.899506  0.916173\n",
      "10      0.831225    0.807674  0.922293  0.841860\n",
      "11      0.781404    0.785269  0.954655  0.677469\n",
      "12      0.879920    0.882190  0.951847  0.959042\n",
      "13      0.894119    0.890205  0.930122  0.873553\n",
      "14      0.789746    0.841553  0.904689  0.812583\n",
      "15      0.832228    0.832846  0.898599  0.909954\n",
      "16      0.872531    0.854949  0.894021  0.873275\n",
      "17      0.892607    0.882697  0.921886  0.884679\n",
      "18      0.930662    0.919197  0.967828  0.928587\n",
      "19      0.932995    0.949145  0.971409  0.817613\n",
      "20      0.925402    0.926833  0.957585  0.922556\n",
      "21      0.747747    0.793802  0.878038  0.860367\n",
      "22      0.841342    0.818552  0.889336  0.746199\n",
      "23      0.880550    0.864826  0.929577  0.832043\n",
      "24      0.892689    0.863669  0.904648  0.790732\n",
      "25      0.822301    0.812707  0.838297  0.746601\n",
      "26      0.849257    0.835093  0.854257  0.752446\n",
      "27      0.812713    0.780450  0.849722  0.666122\n",
      "28      0.748080    0.740960  0.791439  0.665436\n",
      "29      0.924111    0.900917  0.931901  0.926139\n",
      "30      0.727990    0.744236  0.831061  0.860178\n",
      "31      0.800558    0.741619  0.795107  0.878250\n",
      "32      0.881830    0.866721  0.957191  0.847655\n",
      "33      0.914194    0.897828  0.940196  0.850987\n",
      "34      0.905236    0.898187  0.937230  0.859890\n",
      "35      0.907999    0.905595  0.951449  0.882402\n",
      "36      0.896748    0.910498  0.960719  0.946344\n",
      "37      0.965451    0.970875  0.990209  0.831817\n",
      "38      0.914521    0.907017  0.960415  0.932356\n",
      "39      0.945301    0.947968  0.968200  0.880007\n",
      "40      0.727024    0.737893  0.808082  0.696142\n",
      "41      0.755602    0.755186  0.762941  0.743221\n",
      "42      0.909483    0.867918  0.934021  0.903227\n",
      "43      0.906059    0.902001  0.908718  0.830117\n",
      "44      0.830748    0.807951  0.855721  0.778380\n",
      "45      0.893133    0.864328  0.909469  0.926467\n",
      "46      0.830269    0.832191  0.916027  0.889934\n",
      "47      0.851087    0.868509  0.938007  0.925081\n",
      "48      0.703997    0.608467  0.782705  0.828149\n",
      "49      0.949787    0.940770  0.960744  0.794456\n",
      "   AVG Linear Model  AVG SVR_linear  AVG SVR_rbf  AVG SVC_poly\n",
      "0          0.865242        0.855278     0.908855      0.848475\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Model selection\n",
    "model_LM = LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
    "#c_val ลองอย่างน้อย 3 ค่า [0.1, 1, 10, 100]\n",
    "lst = [0.1, 1, 10, 100]\n",
    "c_val = 0\n",
    "AVG_Linear_Model =[]\n",
    "AVG_SVR_linear =[]\n",
    "AVG_SVR_rbf = []\n",
    "AVG_SVC_poly = []\n",
    "for i in lst:\n",
    "    c_val = i\n",
    "    svr_lin = SVR(kernel='linear', C=c_val)\n",
    "    svr_rbf = SVR(kernel='rbf', C=c_val, gamma=0.01)\n",
    "    svr_poly = SVR(kernel='poly', C=c_val, degree=2)\n",
    "    #Calculate accuracy score for each model\n",
    "    score_LM    =  cross_val_score(model_LM, X_train, Y_train, cv=kfold)\n",
    "    score_lin   =  cross_val_score(svr_lin, X_train, Y_train, cv=kfold)\n",
    "    score_rbf   =  cross_val_score(svr_rbf, X_train, Y_train, cv=kfold)\n",
    "    score_poly  =  cross_val_score(svr_poly, X_train, Y_train, cv=kfold)\n",
    "    # View score k-fold\n",
    "    # Valication score comparison\n",
    "    score = pd.DataFrame({'Linear Model':score_LM,'SVR_linear':score_lin, 'SVR_rbf': score_rbf, 'SVR_poly':\n",
    "    score_poly})\n",
    "    score_mean = pd.DataFrame({'AVG Linear Model':[score_LM.mean()],'AVG SVR_linear':[score_lin.mean()],\n",
    "    'AVG SVR_rbf': [score_rbf.mean()], 'AVG SVC_poly': [score_poly.mean()]})\n",
    "    print(score)\n",
    "    print(score_mean)\n",
    "    #display( plot ( score ))\n",
    "    AVG_Linear_Model.append(score_LM.mean())\n",
    "    AVG_SVR_linear.append(score_lin.mean())\n",
    "    AVG_SVR_rbf.append(score_rbf.mean())\n",
    "    AVG_SVC_poly.append(score_poly.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95130265 0.91718475 0.83625108 0.90520691 0.89435038 0.89608547\n",
      " 0.85686924 0.93779799 0.88856474 0.87982413 0.83122489 0.78140353\n",
      " 0.87992024 0.89411859 0.78974598 0.83222755 0.8725311  0.89260651\n",
      " 0.93066162 0.93299464 0.9254019  0.74774703 0.84134167 0.88055021\n",
      " 0.89268856 0.822301   0.84925741 0.81271251 0.74808046 0.92411096\n",
      " 0.72798966 0.8005578  0.88183041 0.91419409 0.90523634 0.90799947\n",
      " 0.89674816 0.96545144 0.91452083 0.94530141 0.72702425 0.75560231\n",
      " 0.9094828  0.90605923 0.83074836 0.89313266 0.83026911 0.85108665\n",
      " 0.70399687 0.94978737]\n",
      "[0.94256874 0.90740257 0.78218866 0.90012087 0.86114166 0.89590985\n",
      " 0.83735193 0.93245124 0.89645283 0.84901328 0.80767427 0.7852686\n",
      " 0.8821898  0.89020521 0.84155344 0.83284559 0.85494899 0.88269685\n",
      " 0.91919726 0.94914459 0.92683262 0.79380163 0.8185524  0.86482615\n",
      " 0.86366902 0.8127071  0.83509345 0.78045043 0.74095953 0.90091722\n",
      " 0.74423613 0.74161925 0.86672087 0.89782845 0.89818739 0.90559484\n",
      " 0.91049833 0.97087525 0.90701727 0.94796848 0.73789342 0.75518643\n",
      " 0.86791802 0.90200086 0.8079505  0.86432754 0.83219113 0.8685093\n",
      " 0.60846666 0.9407704 ]\n",
      "[0.96655763 0.93643116 0.86871256 0.93917472 0.91803388 0.92418117\n",
      " 0.89504703 0.95245065 0.93228667 0.89950636 0.92229304 0.95465497\n",
      " 0.95184673 0.93012247 0.90468867 0.89859897 0.89402128 0.92188609\n",
      " 0.96782849 0.97140933 0.95758522 0.87803783 0.88933602 0.9295775\n",
      " 0.90464752 0.83829712 0.85425651 0.84972165 0.79143911 0.93190094\n",
      " 0.83106058 0.79510748 0.95719136 0.94019617 0.93722958 0.95144877\n",
      " 0.96071883 0.99020873 0.96041533 0.96819955 0.8080816  0.76294136\n",
      " 0.93402127 0.90871752 0.85572058 0.90946866 0.9160266  0.9380067\n",
      " 0.78270455 0.96074396]\n",
      "[0.92196893 0.91789557 0.8919394  0.81828454 0.94209977 0.87112929\n",
      " 0.84802703 0.88934303 0.83458788 0.91617345 0.84185962 0.67746889\n",
      " 0.95904174 0.87355273 0.81258287 0.90995405 0.87327515 0.88467949\n",
      " 0.9285873  0.81761345 0.92255573 0.86036671 0.74619855 0.83204329\n",
      " 0.7907319  0.74660115 0.7524461  0.66612198 0.66543613 0.92613859\n",
      " 0.86017828 0.87825013 0.84765533 0.85098726 0.85988996 0.88240187\n",
      " 0.94634445 0.83181672 0.93235619 0.88000749 0.69614153 0.74322103\n",
      " 0.9032268  0.83011735 0.77838013 0.92646742 0.88993425 0.92508062\n",
      " 0.82814931 0.79445624]\n"
     ]
    }
   ],
   "source": [
    "print(score_LM)\n",
    "print(score_lin)\n",
    "print(score_rbf)\n",
    "print(score_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Linear Model  SVR_linear   SVR_rbf  SVR_poly\n",
      "0       0.951303    0.942569  0.966558  0.921969\n",
      "1       0.917185    0.907403  0.936431  0.917896\n",
      "2       0.836251    0.782189  0.868713  0.891939\n",
      "3       0.905207    0.900121  0.939175  0.818285\n",
      "4       0.894350    0.861142  0.918034  0.942100\n",
      "5       0.896085    0.895910  0.924181  0.871129\n",
      "6       0.856869    0.837352  0.895047  0.848027\n",
      "7       0.937798    0.932451  0.952451  0.889343\n",
      "8       0.888565    0.896453  0.932287  0.834588\n",
      "9       0.879824    0.849013  0.899506  0.916173\n",
      "10      0.831225    0.807674  0.922293  0.841860\n",
      "11      0.781404    0.785269  0.954655  0.677469\n",
      "12      0.879920    0.882190  0.951847  0.959042\n",
      "13      0.894119    0.890205  0.930122  0.873553\n",
      "14      0.789746    0.841553  0.904689  0.812583\n",
      "15      0.832228    0.832846  0.898599  0.909954\n",
      "16      0.872531    0.854949  0.894021  0.873275\n",
      "17      0.892607    0.882697  0.921886  0.884679\n",
      "18      0.930662    0.919197  0.967828  0.928587\n",
      "19      0.932995    0.949145  0.971409  0.817613\n",
      "20      0.925402    0.926833  0.957585  0.922556\n",
      "21      0.747747    0.793802  0.878038  0.860367\n",
      "22      0.841342    0.818552  0.889336  0.746199\n",
      "23      0.880550    0.864826  0.929577  0.832043\n",
      "24      0.892689    0.863669  0.904648  0.790732\n",
      "25      0.822301    0.812707  0.838297  0.746601\n",
      "26      0.849257    0.835093  0.854257  0.752446\n",
      "27      0.812713    0.780450  0.849722  0.666122\n",
      "28      0.748080    0.740960  0.791439  0.665436\n",
      "29      0.924111    0.900917  0.931901  0.926139\n",
      "30      0.727990    0.744236  0.831061  0.860178\n",
      "31      0.800558    0.741619  0.795107  0.878250\n",
      "32      0.881830    0.866721  0.957191  0.847655\n",
      "33      0.914194    0.897828  0.940196  0.850987\n",
      "34      0.905236    0.898187  0.937230  0.859890\n",
      "35      0.907999    0.905595  0.951449  0.882402\n",
      "36      0.896748    0.910498  0.960719  0.946344\n",
      "37      0.965451    0.970875  0.990209  0.831817\n",
      "38      0.914521    0.907017  0.960415  0.932356\n",
      "39      0.945301    0.947968  0.968200  0.880007\n",
      "40      0.727024    0.737893  0.808082  0.696142\n",
      "41      0.755602    0.755186  0.762941  0.743221\n",
      "42      0.909483    0.867918  0.934021  0.903227\n",
      "43      0.906059    0.902001  0.908718  0.830117\n",
      "44      0.830748    0.807951  0.855721  0.778380\n",
      "45      0.893133    0.864328  0.909469  0.926467\n",
      "46      0.830269    0.832191  0.916027  0.889934\n",
      "47      0.851087    0.868509  0.938007  0.925081\n",
      "48      0.703997    0.608467  0.782705  0.828149\n",
      "49      0.949787    0.940770  0.960744  0.794456\n",
      "   AVG Linear Model  AVG SVR_linear  AVG SVR_rbf  AVG SVC_poly\n",
      "0          0.865242        0.855278     0.908855      0.848475\n"
     ]
    }
   ],
   "source": [
    "# View score k-fold\n",
    "# Valication score comparison\n",
    "score = pd.DataFrame({'Linear Model':score_LM,'SVR_linear':score_lin, 'SVR_rbf': score_rbf, 'SVR_poly':\n",
    "score_poly})\n",
    "score_mean = pd.DataFrame({'AVG Linear Model':[score_LM.mean()],'AVG SVR_linear':[score_lin.mean()],\n",
    "'AVG SVR_rbf': [score_rbf.mean()], 'AVG SVC_poly': [score_poly.mean()]})\n",
    "print(score)\n",
    "print(score_mean)\n",
    "#display( plot ( score ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4991.600106517938\n",
      "-5.478001844628336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Predict all models ( LM, SVR_linear, SVR_rbf, SVR Poly )\n",
    "LM_pred = model_LM.fit(X_train, Y_train).predict(X_test)\n",
    "# Model prediction performance evaluation for all model ( LM, SVR_linear, SVR_rbf, SVR Poly )\n",
    "#MSE \n",
    "LM_MSE = metrics.mean_squared_error(Y_test, LM_pred)\n",
    "#R2\n",
    "LM_r2 = metrics.r2_score(Y_test, LM_pred)\n",
    "print(LM_MSE)\n",
    "print(LM_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369\n",
      "     (Adj Close, IBM)   DEXJPUS   DEXUSUK      DJIA    VIXCLS  MSFT_3DT  \\\n",
      "0           -0.156398 -0.424727  1.346157  0.904799  0.244178  0.338824   \n",
      "1           -0.216384 -0.443584  1.485797  0.950367  0.169448  0.025317   \n",
      "2           -0.177764 -0.385667  1.390980  1.021182  0.029187  0.148292   \n",
      "3           -0.098052 -0.353341  1.289267  1.063427 -0.046692 -0.783561   \n",
      "4           -0.125993 -0.366810  1.334089  1.032614 -0.074284 -1.349951   \n",
      "..                ...       ...       ...       ...       ...       ...   \n",
      "364          1.786638  3.316975 -2.196569  1.052826  0.422379 -1.539710   \n",
      "365          1.647105  3.392402 -2.268975  1.067237  0.274069 -1.927336   \n",
      "366          1.716409  3.380280 -2.267251  1.145181  0.154502 -2.860450   \n",
      "367          1.383751  3.412605 -2.310350  0.901508  0.589083 -1.236271   \n",
      "368          1.377282  3.637538 -2.413787  0.856946  0.663812 -0.922314   \n",
      "\n",
      "     MSFT_6DT  MSFT_12DT  \n",
      "0   -0.328503   0.205123  \n",
      "1   -0.969142  -0.342538  \n",
      "2   -0.083850  -0.527544  \n",
      "3    0.235205  -0.080213  \n",
      "4   -0.397864   0.258509  \n",
      "..        ...        ...  \n",
      "364 -2.025844  -1.285195  \n",
      "365 -2.079481  -1.020488  \n",
      "366 -3.024489  -2.672114  \n",
      "367 -2.009242  -1.647769  \n",
      "368 -1.025925  -2.018734  \n",
      "\n",
      "[369 rows x 8 columns]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_8808\\2014962221.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test.drop(columns = [X_test.columns[0]],inplace = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4991.600106517938\n",
      "-5.478001844628336\n",
      "15152.53556200841\n",
      "-18.664666885737475\n",
      "24341.36976946309\n",
      "-30.589757773556865\n",
      "24341.36976946309\n",
      "-30.589757773556865\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "c_val = 0.1\n",
    "svr_lin = SVR(kernel='linear', C=c_val)\n",
    "svr_rbf = SVR(kernel='rbf', C=c_val, gamma=0.01)\n",
    "svr_poly = SVR(kernel='poly', C=c_val, degree=2)\n",
    "LM_pred = model_LM.fit(X_train, Y_train).predict(X_test)\n",
    "svr_lin_pred = svr_lin.fit(X_train,Y_train).predict(X_test)\n",
    "svr_rbf_pred = svr_rbf.fit(X_train,Y_train).predict(X_test)\n",
    "svr_poly_pred = svr_rbf.fit(X_train,Y_train).predict(X_test)\n",
    "X_test.reset_index(inplace = True)\n",
    "X_test.drop(columns = [X_test.columns[0]],inplace = True)\n",
    "print(len(LM_pred))\n",
    "print(X_test)\n",
    "# plt.scatter(X_test[\"DEXJPUS\"],LM_pred, c='magenta')\n",
    "# plt.show()\n",
    "LM_MSE = metrics.mean_squared_error(Y_test, LM_pred)\n",
    "LM_r2 = metrics.r2_score(Y_test, LM_pred)\n",
    "print (LM_MSE)\n",
    "print(LM_r2)\n",
    "\n",
    "svr_lin_MSE = metrics.mean_squared_error(Y_test, svr_lin_pred)\n",
    "svr_lin_r2 = metrics.r2_score(Y_test, svr_lin_pred)\n",
    "print (svr_lin_MSE)\n",
    "print(svr_lin_r2)\n",
    "\n",
    "\n",
    "svr_rbf_MSE = metrics.mean_squared_error(Y_test, svr_rbf_pred)\n",
    "svr_rbf_r2 = metrics.r2_score(Y_test, svr_rbf_pred)\n",
    "print (svr_rbf_MSE)\n",
    "print(svr_rbf_r2)\n",
    "\n",
    "svr_poly_MSE = metrics.mean_squared_error(Y_test, svr_poly_pred)\n",
    "svr_poly_r2 = metrics.r2_score(Y_test, svr_poly_pred)\n",
    "print (svr_poly_MSE)\n",
    "print(svr_poly_r2)\n",
    "\n",
    "# plt.bar([\"LM_MSE\",\"svr_lin_MSE\",\"svr_rbf_MSE\",\"svr_poly_MSE\"],[LM_MSE,svr_lin_MSE,svr_rbf_MSE,svr_poly_MSE])\n",
    "plt.bar([\"LM_r2\",\"svr_lin_r2\",\"svr_rbf_r2\",\"svr_poly_r2\"],[LM_r2,svr_lin_r2,svr_rbf_r2,svr_poly_r2])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
