{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.1 Data preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          userId  movieId  rating   timestamp                         title  \\\n",
      "0              1      296     5.0  1147880044           Pulp Fiction (1994)   \n",
      "1              3      296     5.0  1439474476           Pulp Fiction (1994)   \n",
      "2              4      296     4.0  1573938898           Pulp Fiction (1994)   \n",
      "3              5      296     4.0   830786155           Pulp Fiction (1994)   \n",
      "4              7      296     4.0   835444730           Pulp Fiction (1994)   \n",
      "...          ...      ...     ...         ...                           ...   \n",
      "25000090  162358   200192     2.0  1553453039   Den frusna leoparden (1986)   \n",
      "25000091  162358   200194     2.0  1553453843             Tough Luck (2004)   \n",
      "25000092  162386   139970     3.5  1549215965  I Don't Speak English (1995)   \n",
      "25000093  162386   200726     4.0  1554651417          The Graduates (1995)   \n",
      "25000094  162386   200728     4.0  1554651472    Il pesce innamorato (1999)   \n",
      "\n",
      "                               genres  \n",
      "0         Comedy|Crime|Drama|Thriller  \n",
      "1         Comedy|Crime|Drama|Thriller  \n",
      "2         Comedy|Crime|Drama|Thriller  \n",
      "3         Comedy|Crime|Drama|Thriller  \n",
      "4         Comedy|Crime|Drama|Thriller  \n",
      "...                               ...  \n",
      "25000090           (no genres listed)  \n",
      "25000091    Action|Adventure|Thriller  \n",
      "25000092                       Comedy  \n",
      "25000093               Children|Drama  \n",
      "25000094           (no genres listed)  \n",
      "\n",
      "[25000095 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read data from 2 files:\n",
    "df_R = pd.read_csv('ratings.csv')\n",
    "df_M = pd.read_csv('movies.csv')\n",
    "\n",
    "#Join dataframe rating and movie\n",
    "df = pd.merge(df_R,df_M)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preapare Train, validation data\n",
    "df_train, df_val = train_test_split(df, train_size=0.007,test_size=0.003, stratify=df['rating'])#using option stratify=df.rating\n",
    "\n",
    "# Re-numbering userId ( to eliminate skipping id)\n",
    "userId_list = list(set(df['userId']))\n",
    "index = 0\n",
    "dict_users = {}\n",
    "for ids in sorted(userId_list):\n",
    "    dict_users.update ({ids : index})\n",
    "    index += 1\n",
    "\n",
    "# Re-numbering movieId\n",
    "movieId_list = list(set(df['movieId']))\n",
    "index = 0\n",
    "dict_movies = {}\n",
    "for ids in sorted(movieId_list):\n",
    "    dict_movies.update ({ids : index})\n",
    "    index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map new id to train, validation for both “userId”, “movieId”\n",
    "df_train[\"userId\"] = df_train[\"userId\"].map(dict_users)\n",
    "df_train[\"movieId\"] = df_train[\"movieId\"].map(dict_movies)\n",
    "df_val[\"userId\"] = df_val[\"userId\"].map(dict_users)\n",
    "df_val[\"movieId\"] = df_val[\"movieId\"].map(dict_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unique_users = len(userId_list)\n",
    "num_unique_movies = len(movieId_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.2 model preparing and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Create Model NCF\n",
    "EMBEDDING_SIZE=100\n",
    "users_input = Input(shape=(1,), name=\"users_input\")\n",
    "users_embedding = Embedding(num_unique_users + 1, EMBEDDING_SIZE,name=\"users_embeddings\")(users_input)\n",
    "users_bias = Embedding(num_unique_users + 1, 1, name=\"users_bias\")(users_input)\n",
    "movies_input = Input(shape=(1,), name=\"movies_input\")\n",
    "movies_embedding = Embedding(num_unique_movies + 1, EMBEDDING_SIZE,name=\"movies_embeddings\")(movies_input)\n",
    "movies_bias = Embedding(num_unique_movies + 1, 1, name=\"movies_bias\")(movies_input)\n",
    "dot_product_users_movies = tf.math.multiply(users_embedding, movies_embedding)\n",
    "input_terms = dot_product_users_movies + users_bias + movies_bias\n",
    "input_terms = Flatten(name=\"fl_inputs\")(input_terms)\n",
    "output = Dense(1, activation=\"relu\", name=\"output\")(input_terms)\n",
    "model = Model(inputs=[users_input, movies_input], outputs=output)\n",
    "opt_adam = Adam(lr = 0.005)\n",
    "model.compile(optimizer=opt_adam, loss= ['mse'], metrics=['mean_absolute_error'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " users_input (InputLayer)       [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " movies_input (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " users_embeddings (Embedding)   (None, 1, 100)       16254200    ['users_input[0][0]']            \n",
      "                                                                                                  \n",
      " movies_embeddings (Embedding)  (None, 1, 100)       5904800     ['movies_input[0][0]']           \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 1, 100)       0           ['users_embeddings[0][0]',       \n",
      "                                                                  'movies_embeddings[0][0]']      \n",
      "                                                                                                  \n",
      " users_bias (Embedding)         (None, 1, 1)         162542      ['users_input[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 1, 100)      0           ['tf.math.multiply[0][0]',       \n",
      " da)                                                              'users_bias[0][0]']             \n",
      "                                                                                                  \n",
      " movies_bias (Embedding)        (None, 1, 1)         59048       ['movies_input[0][0]']           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 1, 100)      0           ['tf.__operators__.add[0][0]',   \n",
      " mbda)                                                            'movies_bias[0][0]']            \n",
      "                                                                                                  \n",
      " fl_inputs (Flatten)            (None, 100)          0           ['tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            101         ['fl_inputs[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 22,380,691\n",
      "Trainable params: 22,380,691\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ------------ View Model Summary -------------------------------\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ Training Model -------------------------------\n",
    "BS = [512,1024,2048] #[64, 128, 256, 512, 1024, 2048] # try at least 3 values\n",
    "EP = [10,20,50] #[5, 10, 20, 50, 60 ] # try at least 3 values\n",
    "# history = model.fit(x=[df_train.userId, df_train.movieId],y=df_train.rating,batch_size=BS,epochs=EP,verbose=1,validation_data=([df_val.userId, df_val.movieId], df_val.rating))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 76/342 [=====>........................] - ETA: 50s - loss: 7.4630 - mean_absolute_error: 2.3567"
     ]
    }
   ],
   "source": [
    "for i in range(len(BS)):    \n",
    "    history = model.fit(x=[df_train.userId, df_train.movieId],y=df_train.rating,batch_size=BS[i],epochs=EP[i],verbose=1,validation_data=([df_val.userId, df_val.movieId], df_val.rating))    \n",
    "    # ------------ Visualize loss -------------------------------\n",
    "    plt.plot(history.history[\"mean_absolute_error\"],'y',linewidth=2,label ='train')\n",
    "    plt.plot(history.history[\"val_mean_absolute_error\"],'m',linewidth=2,label ='test')\n",
    "    plt.title('model loss mean absolute error')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('mean absolute error')\n",
    "    plt.legend()\n",
    "    fig_name = (f'../Picture/Lab11/MAE_Bs{BS[i]}_Ep{EP[i]}.png')\n",
    "    plt.savefig(fig_name,dpi=500)\n",
    "    plt.show()\n",
    "    plt.plot(history.history[\"loss\"],'y',linewidth=2,label ='train')\n",
    "    plt.plot(history.history[\"val_loss\"],'m',linewidth=2,label ='test')\n",
    "    plt.title('model loss MSE')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('mean square error')\n",
    "    plt.legend()\n",
    "    fig_name = (f'../Picture/Lab11/MSE_Bs{BS[i]}_Ep{EP[i]}.png')\n",
    "    plt.savefig(fig_name,dpi=500)\n",
    "    plt.show()\n",
    "    out_path = f'../Picture/Lab11/predict_Bs{BS[i]}_Ep{EP[i]}.csv'\n",
    "    userPredictR = pd.DataFrame(model.predict([df_val.userId, df_val.movieId]))\n",
    "    pd.DataFrame.to_csv(userPredictR,out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2344/2344 [==============================] - 1s 566us/step\n"
     ]
    }
   ],
   "source": [
    "# ------------ Model Prediction -------------------------------\n",
    "userPredictR = pd.DataFrame(model.predict([df_val.userId, df_val.movieId]))\n",
    "userPredictR\n",
    "pd.DataFrame.to_csv(userPredictR,f'../Picture/Lab11/predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Work\\3DS1\\ML\\Lab\\Lab11.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Work/3DS1/ML/Lab/Lab11.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m\"\u001b[39m\u001b[39mmean_absolute_error\u001b[39m\u001b[39m\"\u001b[39m],\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m,linewidth\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,label \u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Work/3DS1/ML/Lab/Lab11.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m\"\u001b[39m\u001b[39mval_mean_absolute_error\u001b[39m\u001b[39m\"\u001b[39m],\u001b[39m'\u001b[39m\u001b[39mm\u001b[39m\u001b[39m'\u001b[39m,linewidth\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,label \u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Work/3DS1/ML/Lab/Lab11.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mmodel loss mean absolute error\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# plt.plot(history.history[\"mean_absolute_error\"],'y',linewidth=2,label ='train')\n",
    "# plt.plot(history.history[\"val_mean_absolute_error\"],'m',linewidth=2,label ='test')\n",
    "# plt.title('model loss mean absolute error')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('mean absolute error')\n",
    "# plt.legend()\n",
    "# plt.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
